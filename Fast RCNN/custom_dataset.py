# -*- coding: utf-8 -*-
"""custom_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17-CtfLgpCbsB8LiLrPMkeK-LpNKxMutf
"""

# !pip install -q --upgrade selectivesearch torch_snippets

from torch_snippets import *
import selectivesearch
from google.colab import files
from torchvision import transforms, models, datasets
from torch_snippets import Report
from torchvision.ops import nms

class OpenImages(Dataset):
    def __init__(self, df, image_folder='/content/images/images'):
        self.root = image_folder
        self.df = df
        self.unique_images = df['ImageID'].unique()

    def __len__(self): 
        return len(self.unique_images)

    def __getitem__(self, ix):
        image_id = self.unique_images[ix]
        image_path = f'{self.root}/{image_id}.jpg' 
        image = cv2.imread(image_path, 1)[...,::-1] # Convert BGR to RGB
        h, w, _ = image.shape
        df = self.df.copy()
        df = df[df['ImageID'] == image_id]
        boxes = df['XMin,YMin,XMax,YMax'.split(',')].values
        boxes = (boxes*np.array([w,h,w,h])).astype(np.uint16).tolist()
        classes = df['LabelName'].values.tolist()
        return image, boxes, classes, image_path






# class FRCNNDataset(Dataset):
#     def __init__(self, fpaths, rois, labels, deltas, gtbbs, device='cuda', label2target):
#         self.fpaths = fpaths
#         self.gtbbs = gtbbs
#         self.rois = rois
#         self.labels = labels
#         self.deltas = deltas

#     def __len__(self): 
#         return len(self.fpaths)
    
#     def __getitem__(self, ix):
#         fpath = str(self.fpaths[ix])
#         image = cv2.imread(fpath, 1)[...,::-1]
#         gtbbs = self.gtbbs[ix]
#         rois = self.rois[ix]
#         labels = self.labels[ix]
#         deltas = self.deltas[ix]
#         assert len(rois) == len(labels) == len(deltas), f'{len(rois)}, {len(labels)}, {len(deltas)}'
#         return image, rois, labels, deltas, gtbbs, fpath
    
#     def collate_fn(self, batch):
#         input, rois, rixs, labels, deltas = [],[],[],[],[]
#         for ix in range(len(batch)):
#             image, image_rois, image_labels, image_deltas, image_gt_bbs, image_fpath = batch[ix]
#             image = cv2.resize(image, (224,224))
#             input.append(preprocess_image(image/255.)[None])
#             rois.extend(image_rois)
#             rixs.extend([ix]*len(image_rois))
#             labels.extend([label2target[c] for c in image_labels])
#             deltas.extend(image_deltas) 
#         input = torch.cat(input).to(device)
#         rois = torch.Tensor(rois).float().to(device)
#         rixs = torch.Tensor(rixs).float().to(device)
#         labels = torch.Tensor(labels).long().to(device)
#         deltas = torch.Tensor(deltas).float().to(device)
#         return input, rois, rixs, labels, deltas         




